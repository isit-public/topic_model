{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from   collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from   pandas.io.json import json_normalize\n",
    "from   pandas import Series, DataFrame\n",
    "\n",
    "import nltk\n",
    "\n",
    "import gensim\n",
    "from   gensim import corpora, models\n",
    "from   nltk.stem.porter import PorterStemmer\n",
    "from   nltk import stem\n",
    "from   nltk.corpus import stopwords\n",
    "\n",
    "#clustering tools\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.feature_extraction.text import CountVectorizer\n",
    "from   sklearn.cluster import KMeans\n",
    "from   sklearn.cluster import DBSCAN\n",
    "import hdbscan\n",
    "\n",
    "import MeCab\n",
    "m  = MeCab.Tagger(\"\")\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本プログラムで使用するライブラリを設定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ORG_LIST_FILE      = 'org_name_list.json'\n",
    "MYLIB_STOPWORD     = 'MyStopWords.txt'\n",
    "DICTIONARY_FILE    = 'dictionary.dict'\n",
    "CORPUS_FILE        = 'od_corpus.mm'\n",
    "LDA_MODEL_FILE     = 'lda_52_sixty_good_model'\n",
    "\n",
    "NUM_PAGE           = 218\n",
    "NUM_PER_REQ        = 100\n",
    "\n",
    "RESULT_HOME_DIR    = '/home/nyoshimatsu/work/odcs/analysis/'\n",
    "RESULT_G_NAME      = 'g'\n",
    "RESULT_V_NAME      = 'v'\n",
    "RESULT_D_NAME      = 'd'\n",
    "RESULT_M_NAME      = 'm'\n",
    "WORK_DIR           = '/home/nyoshimatsu/work/odcs/harvest/'\n",
    "SCRIPT_DIR         = WORK_DIR + 'scripts/topic/'\n",
    "\n",
    "DIRNAME            = 'default'\n",
    "\n",
    "RESULT_G_DIR       = RESULT_HOME_DIR + DIRNAME + '/' + RESULT_G_NAME + '/'\n",
    "RESULT_V_DIR       = RESULT_HOME_DIR + DIRNAME + '/' + RESULT_V_NAME + '/'\n",
    "RESULT_D_DIR       = RESULT_HOME_DIR + DIRNAME + '/' + RESULT_D_NAME + '/'\n",
    "RESULT_M_DIR       = RESULT_HOME_DIR + DIRNAME + '/' + RESULT_M_NAME + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラム内で使用する定数、ディレクトリ名、ファイル名を設定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# defs\n",
    "#######################################\n",
    "\n",
    "def load_mystopwords():\n",
    "    file_name    = RESULT_V_DIR + MYLIB_STOPWORD\n",
    "    ff            = open( file_name, 'r' )\n",
    "\n",
    "    mylib_stopwords = []\n",
    "    for line in ff:\n",
    "        line = line.strip()\n",
    "        mylib_stopwords.append(line)\n",
    "\n",
    "    ff.close()\n",
    "\n",
    "    return(mylib_stopwords)\n",
    "\n",
    "def load_stopwords():\n",
    "    url = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        slothlib_stopwords = [w for w in response.read().decode().split('\\r\\n') if w != '']\n",
    "\n",
    "    return(slothlib_stopwords)\n",
    "\n",
    "def mash_lists(marged_list):\n",
    "\n",
    "    mashed_str = marged_list\n",
    "    \n",
    "    mashed_str  = mashed_str.replace( \"],\", \"\")\n",
    "    mashed_str  = mashed_str.replace( \"]\", \"\")\n",
    "    mashed_str  = mashed_str.replace( \"[\", \"\")\n",
    "    mashed_str  = mashed_str.replace( \"'\", \"\")\n",
    "    mashed_str  = re.sub( \",\\Z\", \"\", mashed_str)\n",
    "    mashed_list = mashed_str.split(\",\")\n",
    "\n",
    "    return(mashed_list)\n",
    "\n",
    "def calculate_topic_pop(df):\n",
    "    results_dict = {}\n",
    "    \n",
    "    for row_num in df.index:\n",
    "        for tup in df.topic_comp[row_num]:\n",
    "            if not tup[0] in results_dict:\n",
    "                if tup[1] >= 0.1:\n",
    "                    results_dict[tup[0]] = (tup[1] * (df.iloc[row_num].download_count + \n",
    "                                             df.iloc[row_num].page_views_total_log))\n",
    "                else:\n",
    "                    pass\n",
    "            if tup[0] in results_dict:\n",
    "                if tup[1] >= 0.1:\n",
    "                    results_dict[tup[0]] += (tup[1] * (df.iloc[row_num].download_count + \n",
    "                                             df.iloc[row_num].page_views_total_log))\n",
    "    return results_dict\n",
    "  \n",
    "def clensing_basic(w):\n",
    "    w = w.replace('（', '')\n",
    "    w = w.replace('）', '')\n",
    "    w = w.replace('(' , '')\n",
    "    w = w.replace(')' , '')\n",
    "    w = w.replace(',' , '')\n",
    "    w = w.replace('、', '')\n",
    "    w = w.replace('，', '')\n",
    "    w = w.replace('\" ', '')\n",
    "    w = w.replace('\"' , '')\n",
    "    w = w.replace('「', '')\n",
    "    w = w.replace('」', '')\n",
    "    return w\n",
    "\n",
    "def wakachi(content):\n",
    "    word_list     = []\n",
    "    wakachi_words = \"\"\n",
    "\n",
    "    if not content == '':\n",
    "        parsed_content = m.parse(content)\n",
    "        parsed_lines   = re.split('\\n', parsed_content)\n",
    "\n",
    "        for parsed_line in parsed_lines:\n",
    "            parsed_words1 = re.split('[ \\t]+', parsed_line)\n",
    "            parsed_word   = parsed_words1[0]\n",
    "\n",
    "            if len(parsed_words1) > 1:\n",
    "                parsed_words2 = re.split('\\,', parsed_words1[1])\n",
    "                parsed_part   = parsed_words2[0]\n",
    "\n",
    "               #if parsed_part == '名詞' or parsed_part == '動詞':\n",
    "                if parsed_part == '名詞':\n",
    "                    word_list.append(parsed_word)\n",
    "\n",
    "        wakachi_words = \"\"\n",
    "        for word in word_list:\n",
    "            wakachi_words = wakachi_words + \" \" + word\n",
    "\n",
    "    return(wakachi_words)\n",
    "\n",
    "def find_url(result_dict, org_url_dict, page_data):\n",
    "\n",
    "    num_results    = len (result_dict['result'])\n",
    "  \n",
    "    for i in range(num_results) :\n",
    "        num_resources      = len (result_dict['result'][i]['resources'])\n",
    "        num_tags           = len (result_dict['result'][i]['tags'])\n",
    "\n",
    "        package_author     = result_dict['result'][i]['maintainer']\n",
    "        if package_author is not None :\n",
    "            package_author     = package_author.replace('\\r\\n', '')\n",
    "            package_author     = package_author.replace('\\n',   '')\n",
    "\n",
    "        organization_name  = result_dict['result'][i]['organization']['name']\n",
    "        if  organization_name is not None :\n",
    "            organization_name  = organization_name.replace('\\r\\n', '')\n",
    "            organization_name  = organization_name.replace('\\n',   '')\n",
    "\n",
    "        organization_title = result_dict['result'][i]['organization']['title']\n",
    "        if organization_title is not None :\n",
    "            organization_title = organization_title.replace('\\r\\n', '')\n",
    "            organization_title = organization_title.replace('\\n',   '')\n",
    "\n",
    "        dataset_desc_list  = []\n",
    "        dataset_desc       = result_dict['result'][i]['notes']\n",
    "        if dataset_desc is not None :\n",
    "            dataset_desc     = dataset_desc.replace(',',    '')\n",
    "            dataset_desc     = dataset_desc.replace('\\r\\n', '')\n",
    "            dataset_desc     = dataset_desc.replace('\\n',   '')\n",
    "            dataset_desc     = dataset_desc.strip()\n",
    "\n",
    "            dataset_desc_sep = wakachi(dataset_desc)\n",
    "            dataset_desc     = clensing_basic(dataset_desc_sep)\n",
    " \n",
    "            dataset_desc_list = re.split('[ ]+', dataset_desc)\n",
    "\n",
    "        dataset_name = result_dict['result'][i]['name']\n",
    "        if dataset_name is not None :\n",
    "            dataset_name = dataset_name.replace('\\r\\n', '')\n",
    "            dataset_name = dataset_name.replace('\\n',   '')\n",
    " \n",
    "        group_list   = []\n",
    "        group_domain = ''\n",
    "\n",
    "        tag_list     = []\n",
    "        for j in range(num_tags):\n",
    "            tag        = result_dict['result'][i]['tags'][j]['name']\n",
    "            tag_list.append(tag)\n",
    "\n",
    "        # domain_name = result_dict['result'][i]['url']\n",
    "        domain_name = org_url_dict[organization_name]['url']\n",
    "\n",
    "        mash_list    = []\n",
    "        big_mash_list= []\n",
    "\n",
    "        download_count        = 1\n",
    "        page_views_last_month = 1\n",
    "        page_views_last_week  = 1\n",
    "        page_views_total      = 1\n",
    "        page_views_total_log  = 1\n",
    "            \n",
    "        # update dict data\n",
    "        rsc_data = pd.Series({\n",
    "            'name':                  dataset_name,\n",
    "            'description':           dataset_desc_list,\n",
    "            'attribution':           package_author,\n",
    "            'column_field_name':     '',\n",
    "            'columns_name':          '',\n",
    "            'type':                  'file',\n",
    "            'categories':            group_list,\n",
    "            'domain_category':       group_domain,\n",
    "            'domain_tags':           tag_list,\n",
    "            'provenance':            'official',\n",
    "            'download_count':        download_count,\n",
    "            'page_views_last_month': page_views_last_month,\n",
    "            'page_views_last_week':  page_views_last_week,\n",
    "            'page_views_total':      page_views_total,\n",
    "            'page_views_total_log':  page_views_total_log,\n",
    "            'domain':                domain_name,\n",
    "            'mash':                  mash_list,\n",
    "            'big_mash':              big_mash_list\n",
    "        })\n",
    "    \n",
    "        page_data = page_data.append(rsc_data, ignore_index=True)\n",
    "\n",
    "    return (page_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本プログラムで使用する関数の定義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name    = RESULT_V_DIR + ORG_LIST_FILE\n",
    "f            = open( file_name, 'r' )\n",
    "org_url_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自治体名と自治体コード、および、オープンデータサイトの対応表を読み込み。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pages... \n",
      "   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 Done\n"
     ]
    }
   ],
   "source": [
    "result_dict  = {}\n",
    "\n",
    "pd_data_init = DataFrame(index=[], columns=[\n",
    "    'name',\n",
    "    'description',\n",
    "    'attribution',\n",
    "    'column_field_name',\n",
    "    'columns_name',\n",
    "    'type',\n",
    "    'categories',\n",
    "    'domain_category',\n",
    "    'domain_tags',\n",
    "    'provenance',\n",
    "    'download_count',\n",
    "    'page_views_last_month',\n",
    "    'page_views_last_week',\n",
    "    'page_views_total',\n",
    "    'page_views_total_log',\n",
    "    'domain',\n",
    "    'mash',\n",
    "    'big_mash'\n",
    "])\n",
    "\n",
    "pd_data = pd_data_init\n",
    "\n",
    "print('Loading pages... ')\n",
    "\n",
    "for i in range(NUM_PAGE):\n",
    "\n",
    "    print( \" %3d\" % (i), end=\"\" )\n",
    "  \n",
    "    file_name   = RESULT_G_DIR + 'resource_' + str(i)\n",
    "    f           = open( file_name, 'r' )\n",
    "    result_json = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Check the contents of the response.\n",
    "    assert result_json['success'] is True\n",
    "    result_dict = result_json\n",
    "  \n",
    "    # check_dict(i, result_dict, org_url_dict)\n",
    "\n",
    "    page_data = pd_data_init\n",
    "\n",
    "    page_data = find_url(result_dict, org_url_dict, page_data)\n",
    "\n",
    "    if len(page_data) > 0:\n",
    "        pd_data = pd_data.append(page_data)\n",
    "\n",
    "print(\" Done\")\n",
    "\n",
    "pd_data = pd_data.reset_index(drop=True)\n",
    "\n",
    "read_df = pd_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事前にharvestから取得したCKANデータを、pandasのデータフレームへ読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df             = read_df.copy()\n",
    "df['mash']     = df['domain_tags']\n",
    "df['big_mash'] = df['domain_tags'] + df['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トピックモデルでは、CKANのリソースに付加されている'domain_tags'、および、'domain_tags'と'description'を合わせてた文字列を文書と見立てトピックモデルを適用する。\n",
    "データフレームに、分析に用いるカラムとして'mash'、および、'big_mash'を作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df): 6117\n"
     ]
    }
   ],
   "source": [
    "df = df[df.astype(str).mash != \"[]\"] # drop all blank lists\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "big_mash = df.copy()\n",
    "\n",
    "print(\"len(df):\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'mash'のカラムで、データが無い列を削除する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mash       = df.big_mash\n",
    "slothlib_stopwords = load_stopwords()\n",
    "mylib_stopwords = load_mystopwords()\n",
    "  \n",
    "stop_words = stopwords.words('english')\n",
    "stop       = list(stop_words)\n",
    "stop.append(slothlib_stopwords)\n",
    "stop.extend(['&',''])\n",
    "stop.extend(mylib_stopwords)\n",
    "stop.extend(np.arange(101).astype(str))\n",
    "stop.extend(np.arange(1980, 2025).astype(str))\n",
    "    \n",
    "texts = []\n",
    "\n",
    "for lls in mash:\n",
    "    ls = []\n",
    "    for ll in lls:\n",
    "        ll = ll.strip()\n",
    "        ls.append(ll)\n",
    "      \n",
    "    lowers = [word.lower() for word in ls]\n",
    "    stopped_tokens = [word for word in ls if not word in stop]\n",
    "    texts.append(stopped_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stopwordsの機能を利用し、LDAのモデルから外したい単語を除く。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary      = corpora.Dictionary(texts)\n",
    "dictionary_file = RESULT_M_DIR + DICTIONARY_FILE\n",
    "dictionary.save(dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDAのモデル作成で使用する辞書（各単語に対し番号を割当た対応表）を作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus          = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "corpus_filename = RESULT_M_DIR + CORPUS_FILE\n",
    "corpora.MmCorpus.serialize(corpus_filename, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDAのモデル作成で使用するコーパス（単語IDと単語の出現頻度表）を作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  topics 60  passes\n",
      "[   (   0,\n",
      "        [   ('施設', 0.12758538442331702),\n",
      "            ('位置情報', 0.10602021057806799),\n",
      "            ('子ども', 0.053730517008294496),\n",
      "            ('施設情報', 0.051643867009916911),\n",
      "            ('概要', 0.047763065326178009),\n",
      "            ('学校', 0.027141548716634802),\n",
      "            ('学習', 0.018771338640216371),\n",
      "            ('病院', 0.016334271939516205),\n",
      "            ('経度', 0.01320536245973984),\n",
      "            ('緯度', 0.01320536245973984)]),\n",
      "    (   1,\n",
      "        [   ('調査', 0.050259836666825174),\n",
      "            ('資料', 0.03582394049239887),\n",
      "            ('企業', 0.035465103707183011),\n",
      "            ('工業', 0.029723648100512701),\n",
      "            ('事業所', 0.026217864607823157),\n",
      "            ('各種', 0.025332453963560847),\n",
      "            ('情報', 0.024925753782987631),\n",
      "            ('地図', 0.024196170074210432),\n",
      "            ('目的', 0.021548363145385944),\n",
      "            ('4月1日', 0.019588171403801886)]),\n",
      "    (   2,\n",
      "        [   ('子育て', 0.11192938879439424),\n",
      "            ('施設', 0.043067663067310122),\n",
      "            ('一覧', 0.022981071809485925),\n",
      "            ('規制', 0.022823473376668169),\n",
      "            ('水質', 0.021296267074071805),\n",
      "            ('形質', 0.01715876803212224),\n",
      "            ('調査結果', 0.015906509744017826),\n",
      "            ('営業許可', 0.014558437836252765),\n",
      "            ('検査', 0.013306143812155866),\n",
      "            ('市場', 0.01326794774363349)]),\n",
      "    (   3,\n",
      "        [   ('測量', 0.22361653094793779),\n",
      "            ('地質調査', 0.21345031798864503),\n",
      "            ('柱状図', 0.074262679328097575),\n",
      "            ('ボーリング', 0.064983503417394395),\n",
      "            ('契約', 0.026457912505661364),\n",
      "            ('提供元', 0.01858762387080309),\n",
      "            ('検診', 0.016359782681803547),\n",
      "            ('薬局', 0.010751255947169266),\n",
      "            ('医師会', 0.0093084479532873788),\n",
      "            ('一般社団法人', 0.0093084479532873788)]),\n",
      "    (   4,\n",
      "        [   ('バリアフリー', 0.080671048004551105),\n",
      "            ('地区', 0.063131150513133116),\n",
      "            ('予算', 0.025023030486533079),\n",
      "            ('交通', 0.024254724642512032),\n",
      "            ('基本', 0.022288458897115244),\n",
      "            ('主要', 0.022107938635056095),\n",
      "            ('構想', 0.020885227352746252),\n",
      "            ('処理', 0.018267501846740569),\n",
      "            ('国際', 0.017389632925027147),\n",
      "            ('事業', 0.017191234900386633)]),\n",
      "    (   5,\n",
      "        [   ('国勢調査', 0.11819995015568499),\n",
      "            ('実施', 0.071182757163694085),\n",
      "            ('調査結果', 0.05948644900837663),\n",
      "            ('アンケート', 0.05264855558094398),\n",
      "            ('基準', 0.052102319879587515),\n",
      "            ('10月1日', 0.051261135567056901),\n",
      "            ('5年', 0.041298173044444407),\n",
      "            ('結果', 0.029549539170629288),\n",
      "            ('分配', 0.022807593594140953),\n",
      "            ('随意契約', 0.022415791272583835)]),\n",
      "    (   6,\n",
      "        [   ('港湾', 0.074250773377043),\n",
      "            ('利用', 0.059120126764597734),\n",
      "            ('スポーツ', 0.045304199262426889),\n",
      "            ('上', 0.029042627427193664),\n",
      "            ('ＧＩＳ', 0.02379325968147249),\n",
      "            ('予防接種', 0.022810345620740257),\n",
      "            ('関係機関', 0.019592879421476823),\n",
      "            ('件数', 0.016601710706500929),\n",
      "            ('センサス', 0.016301964920656577),\n",
      "            ('体', 0.014359380235244931)]),\n",
      "    (   7,\n",
      "        [   ('世帯数', 0.14121536510399393),\n",
      "            ('世論調査', 0.08572925521158184),\n",
      "            ('安心-安全', 0.054687108867519423),\n",
      "            ('市民', 0.026014778417591315),\n",
      "            ('経済', 0.024237337317056237),\n",
      "            ('市民経済計算', 0.021457657660400135),\n",
      "            ('農林業', 0.021457657643998491),\n",
      "            ('把握', 0.017188528343663492),\n",
      "            ('構造', 0.016766482320751969),\n",
      "            ('従業者', 0.016384706644064006)]),\n",
      "    (   8,\n",
      "        [   ('健康', 0.20132787834079052),\n",
      "            ('レシピ', 0.075146339258262279),\n",
      "            ('選挙', 0.033206378102621975),\n",
      "            ('消防', 0.033200541311553484),\n",
      "            ('食品', 0.032143851556150974),\n",
      "            ('所在地', 0.025795497083206567),\n",
      "            ('公共施設', 0.017684742615369297),\n",
      "            ('計算', 0.01630076711721274),\n",
      "            ('ごみ', 0.015221941179311312),\n",
      "            ('情報', 0.015101779271987982)]),\n",
      "    (   9,\n",
      "        [   ('市税', 0.16950882726883165),\n",
      "            ('道路', 0.033877686214257963),\n",
      "            ('概況', 0.015945002770957093),\n",
      "            ('状況', 0.015720208800061017),\n",
      "            ('報告', 0.015018048785212663),\n",
      "            ('児童', 0.01419683020498457),\n",
      "            ('年間', 0.014044845335100151),\n",
      "            ('報告書', 0.013544776904475406),\n",
      "            ('職員', 0.011265185785363162),\n",
      "            ('学校', 0.01086550013327737)]),\n",
      "    (   10,\n",
      "        [   ('人口', 0.087728299852444139),\n",
      "            ('世帯', 0.02886501107902166),\n",
      "            ('町名', 0.024743905988413584),\n",
      "            ('算出', 0.024225348068314247),\n",
      "            ('住民基本台帳', 0.02206018360869989),\n",
      "            ('現在', 0.021071504795465958),\n",
      "            ('日程', 0.020860593203123973),\n",
      "            ('動態', 0.018606944451364061),\n",
      "            ('転入', 0.018068497802134688),\n",
      "            ('転出', 0.016868909325018912)]),\n",
      "    (   11,\n",
      "        [   ('財政', 0.18766971267113175),\n",
      "            ('イベント', 0.040559215705172812),\n",
      "            ('ごみ', 0.037674558208149377),\n",
      "            ('収集', 0.036721629762531162),\n",
      "            ('決算', 0.032005853169490811),\n",
      "            ('アニュアルレポート', 0.027002738447406645),\n",
      "            ('ナンバー', 0.022135446660530727),\n",
      "            ('町名', 0.02037128913289547),\n",
      "            ('資料', 0.01451073576341835),\n",
      "            ('以降', 0.011468134109905541)]),\n",
      "    (   12,\n",
      "        [   ('介護', 0.041875663709623916),\n",
      "            ('商業', 0.03395691033407125),\n",
      "            ('一覧', 0.0331109659457803),\n",
      "            ('市民評価アンケート', 0.032655132175117479),\n",
      "            ('改革', 0.032137888967074854),\n",
      "            ('市政', 0.032137888967067582),\n",
      "            ('保育', 0.025264545767770149),\n",
      "            ('指定', 0.024508135479702969),\n",
      "            ('財政', 0.023236791608869149),\n",
      "            ('駐車場', 0.021962264220874904)]),\n",
      "    (   13,\n",
      "        [   ('公開', 0.061751094727587524),\n",
      "            ('作成', 0.055803473283959203),\n",
      "            ('情報', 0.03822660524465718),\n",
      "            ('港湾', 0.029347953775175562),\n",
      "            ('分類', 0.027748510540207747),\n",
      "            ('大阪港', 0.023659437623428019),\n",
      "            ('下水道', 0.021285226226220737),\n",
      "            ('環境', 0.02071590453587073),\n",
      "            ('貨物', 0.017192662724731352),\n",
      "            ('状況', 0.017007781906760906)]),\n",
      "    (   14,\n",
      "        [   ('施設案内', 0.16645161256679269),\n",
      "            ('公園', 0.060867779206972603),\n",
      "            ('市町村', 0.044940481892018443),\n",
      "            ('年報', 0.040480153355054047),\n",
      "            ('毎年', 0.028111745233197292),\n",
      "            ('健康-福祉', 0.023553352416368727),\n",
      "            ('分別', 0.014967113968513333),\n",
      "            ('生産', 0.013994236096832572),\n",
      "            ('更新', 0.013716874739271528),\n",
      "            ('両面', 0.012709351089232514)]),\n",
      "    (   15,\n",
      "        [   ('一覧', 0.041227117863728506),\n",
      "            ('現在', 0.03231855257940313),\n",
      "            ('雪量観測データ', 0.026455527447761033),\n",
      "            ('平成25年', 0.02567563849207927),\n",
      "            ('名称', 0.020779437177571511),\n",
      "            ('調査', 0.017251235828557077),\n",
      "            ('型', 0.016665029805922712),\n",
      "            ('統合', 0.016319755195548985),\n",
      "            ('県域', 0.015819130552897374),\n",
      "            ('岐阜県内', 0.015819130552897374)]),\n",
      "    (   16,\n",
      "        [   ('観光', 0.27895367779347746),\n",
      "            ('様式', 0.032262347074037905),\n",
      "            ('届出', 0.031086996537122661),\n",
      "            ('区域', 0.019977858804869537),\n",
      "            ('不動産', 0.018551115591254382),\n",
      "            ('変更', 0.017348852184496503),\n",
      "            ('港湾', 0.016849667156078461),\n",
      "            ('所得', 0.014135457659788382),\n",
      "            ('イベント', 0.013162240820740852),\n",
      "            ('農林', 0.012170821531836308)]),\n",
      "    (   17,\n",
      "        [   ('種類', 0.025052219055690869),\n",
      "            ('関係', 0.023592854432319729),\n",
      "            ('面積', 0.023384013858868159),\n",
      "            ('避難所', 0.022561772157961461),\n",
      "            ('広報', 0.020615483483363731),\n",
      "            ('防災', 0.020119578110485023),\n",
      "            ('相談', 0.019825991671861963),\n",
      "            ('住宅', 0.017939107876121265),\n",
      "            ('版', 0.016887555652647178),\n",
      "            ('AED', 0.014847963946022662)]),\n",
      "    (   18,\n",
      "        [   ('結果', 0.073542974842151707),\n",
      "            ('水道局', 0.033102910518308597),\n",
      "            ('随意契約', 0.032453220192027198),\n",
      "            ('発注', 0.032285780211160096),\n",
      "            ('業務委託', 0.024644213997265647),\n",
      "            ('計画', 0.022296999073102768),\n",
      "            ('物品', 0.021668270456220964),\n",
      "            ('供給', 0.020525943023430176),\n",
      "            ('発表資料', 0.012596502852906406),\n",
      "            ('入札', 0.012241937205979823)]),\n",
      "    (   19,\n",
      "        [   ('人口', 0.20512455418094486),\n",
      "            ('世帯', 0.10246469459714233),\n",
      "            ('学区', 0.033793390576396479),\n",
      "            ('結果', 0.024699166900205738),\n",
      "            ('男女別', 0.024312723351067836),\n",
      "            ('国勢調査', 0.024161519618017078),\n",
      "            ('一般世帯', 0.023350433215450071),\n",
      "            ('就業者', 0.022889192700634817),\n",
      "            ('集計', 0.020754784698422159),\n",
      "            ('産業', 0.017892177453430424)])]\n"
     ]
    }
   ],
   "source": [
    "topic_N = 20\n",
    "pass_N  = 60\n",
    "\n",
    "print(topic_N,\" topics\", pass_N, \" passes\")\n",
    "\n",
    "lda_52_sixty = gensim.models.ldamodel.LdaModel(\n",
    "    corpus    = corpus,\n",
    "    num_topics= topic_N,\n",
    "    passes    = pass_N,\n",
    "    id2word   = dictionary,\n",
    "    random_state = 7)\n",
    "\n",
    "lda_model = lda_52_sixty.show_topics(num_topics=topic_N, formatted=False)\n",
    "\n",
    "pp.pprint(lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDAのモデルを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model_filename = RESULT_M_DIR + LDA_MODEL_FILE\n",
    "lda_52_sixty.save(lda_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDAのモデルを保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
